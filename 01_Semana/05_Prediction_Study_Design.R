#En la última conferencia aprendimos acerca de los errores dentro y fuera de la muestra, así como sobre el ajuste excesivo. En esta conferencia hablaremos sobre el diseño del estudio de predicción o cómo minimizar los problemas que pueden ser causados por los versículos de muestra y los errores de muestra. 

#Entonces, en el diseño del estudio de predicción, lo primero que debemos hacer es encontrar nuestra tasa de error. Así que en esta lección solo usaremos una tasa de error genérica, pero en la próxima lección hablaremos sobre cuáles son las diferentes tasas de error posibles que puede elegir.  
#Luego, debe dividir sus datos, los datos que usará para construir y validar su modelo en tres componentes, bueno, dos componentes y un componente opcional. Entonces, hay un conjunto de entrenamiento que debe crearse para construir su modelo, un conjunto de pruebas para evaluar su modelo y, opcionalmente, también un conjunto de validación, que también se utilizará para validar su modelo. 

#Entonces, lo que hace es en el conjunto de entrenamiento, elige características usando validación cruzada, por ejemplo. Hablaremos sobre qué es la validación cruzada más adelante en el curso, pero la idea es básicamente usar ese conjunto de entrenamiento para elegir cuáles de las características son más importantes en su modelo. Luego use esa misma técnica para elegir la función de predicción y estimar todos los parámetros que podrían interesarle. 

#Construimos un modelo usando el conjunto de entrenamiento. Si no hay un conjunto de validación, aplicamos el mejor modelo que tenemos a nuestro conjunto de prueba exactamente una vez. Y entonces, ¿por qué solo lo aplicamos una vez? Si aplicamos varios modelos a nuestro conjunto de pruebas, luego, y escogemos el mejor, entonces usamos el conjunto de pruebas, en cierto sentido, para entrenar el modelo. 

#En otras palabras, todavía estamos obteniendo una visión optimista de cuál sería el error de datos en un conjunto de datos completamente nuevo. Por lo tanto, debe aplicar el modelo de predicción al conjunto de prueba exactamente una vez. 

#Si hay un conjunto de validación y un conjunto de prueba, entonces puede aplicar sus mejores modelos de predicción a todo su conjunto de prueba y refinarlos un poco. Entonces, lo que puede encontrar es que algunas características no funcionan tan bien cuando está haciendo una predicción de muestra y puede refinar y ajustar su modelo un poco. Pero ahora, nuevamente, como dije, el error de su conjunto de prueba será un error un poco optimista de cuál será su error real fuera de la muestra. 

#Entonces, lo que hacemos es volver a aplicar nuestro modelo exactamente una vez al conjunto de validación, solo la mejor para obtener nuestra predicción. Entonces, en otras palabras, la idea es que hay un conjunto de datos que se mantiene desde el principio, al que solo aplica exactamente un modelo, y nunca realiza ningún entrenamiento, ajuste o prueba, y eso le dará una buena estimación de sus tasas de error fuera de la muestra. Por lo tanto, un punto importante a tener en cuenta al hacer esto es saber cuáles son los puntos de referencia. Este es un ejemplo de una tabla de clasificación de una competencia. 

#Y, por lo tanto, a menudo le brindan puntos de referencia, marcando en gris aquí en este gráfico que muestra lo que sucede si dice que todos los valores sean iguales a 0. 

#Y es una buena idea saber cuáles son los puntos de referencia de predicción porque a veces si su algoritmo de predicción funciona de manera mejor de lo que debería ser o mucho peor de lo que debería ser, los puntos de referencia le darán una idea de lo que debería estar haciendo mal y le dirán si su algoritmo de predicción se está desviando un poco. 

#Entonces este es el diseño estudiado que se usó en el premio de Netflix, por lo que tenían 100 millones de pares ident-usuario-ident, es decir, películas en las que la gente había dado preferencia. Dividieron eso en un conjunto de datos de entrenamiento, que les iban a dar, usuarios a los que vamos a construir modelos para la predicción. Luego, resistieron, un montón de calificaciones que no se mostrarán en absoluto a las personas que están construyendo los modelos. 

#Entonces, lo que proporcionaron a las personas que estaban construyendo moteles fue un conjunto de capacitación y lo que llamaron un conjunto de datos de prueba. Por lo tanto, entrenaría su modelo en el conjunto de datos de entrenamiento y luego lo aplicaría al conjunto de datos de la sonda para tener una idea de cuál sería el error fuera de muestra, antes de enviarlo a Netflix. 

#Entonces, lo que Netflix haría es tomarían sus predicciones y las aplicarían solo a un conjunto de pruebas. Por lo tanto, no pudo ver este conjunto de cuestionarios y no pudo construir su modelo, pero si le damos una mejor idea de qué tan bien funcionaría su modelo en una muestra, pero en general la gente podría enviar múltiples envíos a este conjunto de cuestionarios y, por lo tanto, es posible que afinen un poco sus modelos y obtengan un rendimiento un poco mejor en el conjunto de cuestionarios. 

#Entonces, lo que finalmente hicieron fue para la evaluación final de todos los diferentes equipos, aplicaron el modelo solo una vez a este conjunto de prueba que se mantuvo hasta el final de la competencia. Y así, al final de la competencia, obtuvieron una estimación imparcial de qué tan bien funcionaría este modelo con un conjunto de datos completamente nuevo que los participantes en la competencia nunca vieron.

#Así que esta idea fue realmente muy importante en el diseño de su estudio y de hecho, resultó que algunos equipos que obtuvieron mejores resultados en el conjunto de pruebas, en realidad no lo hicieron tan bien en el conjunto de pruebas y eso se debió a que estaban ajustando sus modelos o sobreajustando sus modelos al conjunto de pruebas. 

#Así que este es un mensaje importante para llevar a casa, en el sentido de que si está creando modelos de predicción, siempre debe mantener un conjunto de datos y dejarlo completamente a un lado mientras crea sus modelos. Esto ahora lo utilizan los profesionales del grupo, por lo que Kaggle es una empresa que en realidad lleva a cabo muchas competiciones conjuntas para competiciones de predicción para un montón de conjuntos de datos diferentes proporcionados por las empresas. 

#Y siempre hacen un modelo similar en el sentido de que siempre tienen una tabla de líderes que consiste en las predicciones que las personas han enviado para un conjunto de datos de validación que tienen. Pero no es necesariamente el conjunto de datos que usarán para validar sus métodos al final. Ese conjunto de datos se mantiene hasta el final, y cada persona puede aplicar su algoritmo a ese conjunto de datos solo una vez. Algo que debe tener en cuenta es que cuando divide sus conjuntos de datos en conjuntos de entrenamiento, prueba y validación, pueden volverse un poco pequeños, pero debe evitar tamaños de muestra pequeños, especialmente si se trata de la prueba establecer tamaño. Y la razón es, suponga que está prediciendo un resultado binario, por lo que en mi caso, una cosa muy común que se intenta hacer es predecir enfermos versus sanos. 


#Y, en general, podría ser algo así como si las personas harán clic en un anuncio o si no harán clic en un anuncio. Entonces, un clasificador está lanzando una moneda al aire. Siempre puedes lanzar una moneda y decir que se enfermarán si la moneda sale cara y no enfermarán si sale cruz. Entonces, la probabilidad de una clasificación perfecta, usando este algoritmo realmente tonto, se eleva a la mitad al tamaño de la muestra. En otras palabras, la mitad de las veces acertarás, solo por casualidad al lanzar la moneda. Y cada vez, suponiendo que cada predicción sea independiente, cada vez que lances una moneda, obtendrás la mitad de esa cantidad, un número será la disminución en la precisión que obtendrías. Entonces, si fuera pr-, el conjunto de prueba tiene solo una muestra, entonces tiene una probabilidad de 50/50 de obtener esa muestra correctamente. Entonces, incluso si obtuviera una precisión de predicción del 100% en el conjunto de prueba, tendría un 50% de posibilidades de eso, incluso con un lanzamiento de moneda. Con n igual a 2, solo tiene a, solo tiene un 25% de probabilidad de una precisión del 100%. 

#Y con n es igual a 10 en su conjunto de prueba, ahora tiene solo un 0,1% de probabilidad de obtener un 100% de precisión. Entonces, si ve ese 100% de precisión, se sentirá un poco más seguro de que es realmente cierto y no es algo que sea simplemente aleatorio. Entonces, esto sugiere que debemos asegurarnos de que, especialmente, los tamaños de nuestras pruebas sean de tamaño relativamente grande para poder estar seguros de que no solo estamos obteniendo una buena precisión de predicción por casualidad. 

#Así que algunas reglas empíricas, no están escritas en piedra, pero son reglas empíricas razonables que he usado y creo que mucha gente ha usado reglas similares. Por lo tanto, configura, cuando obtiene un nuevo conjunto de datos, si es lo suficientemente grande, configurará el 60% de su conjunto de datos como entrenamiento, el 20% de su conjunto de datos como prueba y el 20% de su conjunto de datos válido para ser validación. 

#De nuevo, se supone que sus conjuntos de datos de prueba y validación no serán demasiado pequeños si lo hace. Si tiene un tamaño de muestra medio, lo que podría hacer es tomar el 60% de su conjunto de datos para entrenar y el 40% de su conjunto de datos para probar. Esto significa que no puede refinar sus modelos en un conjunto de prueba y luego aplicarlos a un conjunto de validación. Pero podría asegurar que su sitio de prueba tenga el tamaño suficiente. 

#Finalmente, si tiene un tamaño de muestra muy pequeño. En primer lugar, puede reconsiderar si tiene suficientes muestras para poder construir un algoritmo de predicción en primer lugar. Pero suponga que está decidido a construir una predicción o un algoritmo de aprendizaje automático, entonces la idea podría ser hacer una validación cruzada e informar la advertencia del tamaño pequeño de la muestra y el hecho de que nunca pudo predecir esto en una muestra o prueba. conjunto de datos. Por lo tanto, algunos principios para recordar son el conjunto de prueba o el conjunto de validación que deben dejarse de lado y nunca deben considerarse al construir su modelo. En otras palabras, necesitaría tener un conjunto de datos al que aplique solo un modelo, solo una vez, y ese conjunto de datos debe ser completamente independiente de cualquier cosa que use para construir el modelo de predicción. En general, desea muestrear aleatoriamente el conjunto de entrenamiento y prueba, y esto puede depender del tipo de muestreo que desee realizar.


#Entonces, por ejemplo, si tiene datos de fuerza de tiempo de ajuste de tiempo, en otras palabras, tiene datos recopilados a lo largo del tiempo, es posible que desee construir su conjunto de entrenamiento en fragmentos de tiempo, pero nuevamente, fragmentos de tiempo aleatorios y construirlos en predicciones aleatorias. Su conjunto de datos refleja en gran medida la estructura del problema. En otras palabras, si desea muestrear cualquier conjunto de datos que pueda tener fuentes de dependencia en el tiempo o en el espacio, necesita muestrear sus datos en fragmentos. Esto se llama backtesting en finanzas. Y es básicamente la idea de que desea poder usar fragmentos de datos que consisten en observaciones a lo largo del tiempo. Todos los subconjuntos deben reflejar la mayor diversidad posible. Si realiza una asignación aleatoria, lo hace. También puede intentar equilibrar por características. Esto puede ser un poco complicado, pero a menudo es una idea útil.

