#Regularizando Regresiones

#Esta conferencia trata sobre la regresión regularizada. Aprendimos sobre la regresión lineal y la regresión lineal generalizada anteriormente. Porque la idea básica aquí es ajustar uno de estos modelos de regresión. Y luego, penalice o reduzca los coeficientes grandes correspondientes a algunas de las variables predictoras. La razón por la que podríamos hacer esto es porque podría ayudar con la compensación de la varianza de sesgo. Si ciertas variables están altamente coordinadas entre sí. Por ejemplo, es posible que no desee incluirlos a ambos en el modelo de regresión lineal, ya que tendrán una varianza muy alta. Lo que podría sesgar levemente su modelo, dejando uno de ellos fuera. En otras palabras, es posible que pierda un poco de capacidad de predicción, pero ahorrará mucho en las variantes y, por lo tanto, mejorará su predicción del error. También puede ayudar con la selección del modelo, en ciertos casos para técnicas de organización regulares como el lazo. Puede ser computacionalmente exigente en grandes conjuntos de datos. Y, en general, parece que no funciona tan bien como los bosques aleatorios o el impulso, cuando se aplica a la predicción en la naturaleza. Por ejemplo, en concursos de ganado. Entonces, como ejemplo motivador, supongamos que ajustamos un modelo de regresión muy simple. Así que hay un resultado Y. Y estamos tratando de predecirlo con dos covariantes, x1 y x2. Tenemos términos de intersección, por lo que es una constante. Más otra constante por x1 más otra constante por x2. >> Así que suponga que x1 y x2 están correlacionados casi perfectamente. En otras palabras, son casi exactamente la misma variable. La palabra para esto en el modelado lineal a menudo se llama colineal. A continuación, puede aproximar este modelo más complicado. Al decir, bueno, ¿qué pasa si incluimos solo X1 y lo multiplicamos por los coeficientes de X1 y X2? No será exactamente correcto, porque X1 y X2 no son exactamente la misma variable. Pero estará muy cerca de la derecha, si X1 y X2 son muy similares entre sí. El resultado puede ser que aún obtenga una muy buena estimación de y. Lo mismo, casi tan bueno como lo hubiera hecho al incluir ambos predictores en el modelo. Y usted, estará un poco sesgado, porque decidimos dejar uno de los predictores fuera. Pero podemos reducir la varianza si esas dos variables están altamente correlacionadas entre sí. Así que aquí hay un ejemplo, con un conjunto de datos de cáncer de próstata y los elementos de la biblioteca de aprendizaje estadístico. Podemos cargar los datos de la próstata y mirar ese conjunto de datos que tiene, 97 observaciones sobre diez variables. Entonces, una cosa que podríamos querer poder hacer es hacer una predicción sobre el cáncer de próstata, el PSA. Basado en una gran cantidad de predictores en el conjunto de datos. Y esto es muy típico de lo que sucede cuando construye estos modelos en la práctica. Así que supongamos que predecimos con todas las combinaciones posibles de variables predictoras. Pasamos al modelo de regresión lineal. Para el resultado donde construimos un modelo de regresión para cada combinación posible de vectores. Entonces podemos ver que el número de predictores aumenta de izquierda a derecha aquí, el error del conjunto de entrenamiento siempre disminuye. Tiene que bajar. A medida que incluya más predictores, el error del conjunto de entrenamiento siempre disminuirá. Pero este es un patrón típico de lo que observa con datos reales. Que los datos del conjunto de prueba, por otro lado, a medida que aumenta el número de predictores, el error del conjunto de prueba disminuye, lo cual es bueno. Pero luego, eventualmente, llega a una meseta y comienza a subir nuevamente. Esto se debe a que estamos sobreajustando los datos en el conjunto de entrenamiento y, eventualmente, es posible que no queramos incluir tantos predictores en nuestro modelo. Este es un patrón increíblemente común. Básicamente, cualquier medida de la complejidad del modelo en el eje x versus la suma de cuadrados residual esperada del error predicho. Puede ver que en el conjunto de entrenamiento casi siempre el error disminuye monótonamente, en otras palabras, a medida que construye. Modelos cada vez más complicados, el error de entrenamiento siempre disminuirá. Pero en un conjunto de prueba, el error disminuirá por un tiempo, eventualmente alcanzará un mínimo. Y luego, comience a aumentar nuevamente a medida que el modelo se vuelve demasiado complejo y se ajusta demasiado a los datos. Entonces, en general, cuál podría ser el mejor enfoque cuando, cuando tenga suficientes datos y tenga suficiente tiempo de cálculo para dividir las muestras. Entonces, la idea es dividir sus datos en conjuntos de entrenamiento, prueba y validación. Trata el conjunto de validación como datos de prueba y entrena todos los modelos competidores posibles. Entonces, todos los subconjuntos posibles en los datos de entrenamiento. Y elija el mejor, el que funcione mejor en el conjunto de datos de validación. Pero ahora que hemos utilizado el conjunto de validación para el entrenamiento, necesitamos evaluar la tasa de error en un conjunto completamente independiente. Por lo tanto, evaluamos adecuadamente este rendimiento aplicando nuestra predicción a los nuevos datos en el conjunto de prueba. A veces, puede volver a realizar la división y el análisis varias veces.


#Para obtener una mejor estimación promedio de cuál será la tasa de error fuera de muestra. Pero hay dos problemas comunes con este enfoque, uno es que puede haber datos limitados. Aquí dividimos la configuración de datos en tres conjuntos de datos diferentes. Puede que no sea posible obtener un ajuste de modelo muy bueno cuando dividimos los datos con tanta precisión. En segundo lugar, está la complejidad computacional. Si está probando todos los subconjuntos posibles de modelos, puede ser muy complicado, especialmente si tiene muchas, muchas variables predictoras. Entonces, otro enfoque es tratar de descomponer el error de predicción. Y vea si hay otra forma en que podamos trabajar directamente para incluir solo la variable que debe incluirse en el modelo. Entonces, si asumimos que la variable y se puede predecir como una función de x, más algún término de error ,. Entonces, el error de predicción esperado es la diferencia esperada entre el resultado y la predicción del resultado al cuadrado. Y entonces, f-hat lambda aquí es la estimación del conjunto de entrenamiento. Usando un conjunto particular de parámetros de ajuste lambda. Entonces, si miramos un nuevo punto. Entonces traemos un nuevo punto de datos y miramos la distancia entre nuestra var, nuestro resultado observado. Y la predicción sobre el nuevo punto de datos. Eso se puede descomponer después de un poco de álgebra en un error irreducible. Esta sigma al cuadrado. El sesgo, por lo que esta es la diferencia entre nuestra predicción esperada y la verdad, y la varianza de nuestra estimación. Entonces, la pregunta, siempre que esté construyendo un modelo de predicción, el objetivo es reducir esta cantidad general. Entonces esto es básicamente lo esperado. Error cuadrático medio entre nuestro resultado y nuestra predicción. Por tanto, el error irreducible no suele reducirse. Su valor es solo parte de los datos que está recopilando. Pero puede intercambiar sesgos y variaciones. Y eso es lo que hace la idea detrás de la regresión regularizada. Entonces, otro problema para los datos de alta dimensión es suponer que solo te estoy mostrando un ejemplo simple de lo que sucede cuando tienes muchos predictores. Así que aquí estoy subconfigurando solo un pequeño subconjunto de los datos de la próstata, así que imagine que solo tengo cinco observaciones en mi conjunto de entrenamiento. Tiene más de cinco variables predictoras. Así que ajusté un modelo lineal que relaciona el resultado con todas estas variables predictoras. Y hay más de cinco. Entonces algunos de ellos obtendrán estimaciones. Pero algunos de ellos serán NA. En otras palabras, r no podrá estimarlos porque tiene más predictores que muestras. Y, entonces, tiene una matriz de diseño que no se puede invertir. Así que aquí tenemos un enfoque para lidiar con este problema si podemos, y el otro problema es tratar de seleccionar nuestro modelo. Podríamos tomar este modelo que tenemos y asumir que tiene una forma lineal, como esta. Así que suponga que es un modelo de regresión lineal, como hemos hablado antes. Y luego restrinja solo la lambda de los coeficientes para que no sean cero. Y luego la pregunta es, después de elegir lambda, así que suponga que solo hay tres coeficientes distintos de cero. Luego tenemos que probar todas las combinaciones posibles de tres coeficientes que no son cero y luego ajustar el mejor modelo. Entonces eso sigue siendo computacionalmente bastante exigente. Entonces, otro enfoque es utilizar la regresión regularizada. Entonces, si la beta j, entonces si nuestros coeficientes que estamos ajustando en el modelo lineal no están restringidos. En otras palabras, no hacemos, no afirmamos que tengan una forma en particular. Pueden explotar si son muy, si tiene variables muy correlacionadas que está utilizando para la predicción. Por tanto, pueden ser susceptibles a una gran variación. Y la alta variación significa que obtendrá predicciones que no son tan precisas. Entonces, para controlar la varianza, podemos regularizar o reducir los coeficientes. Entonces, recuerde que nosotros, lo que podríamos querer minimizar, es algún tipo de distancia entre nuestro resultado que tenemos y nuestro modelo lineal. Entonces, aquí, esta es la distancia entre el resultado y el ajuste al cuadrado del modelo lineal. Esa es la suma residual de cuadrados. Entonces también puede agregar un término de penalización aquí. Es decir, la penalización básicamente dirá: si los coeficientes beta son demasiado grandes, los reducirá. Entonces, la penalización se usa generalmente para reducir la complejidad. Puede usarse para reducir la varianza. Y puede respetar parte de la estructura del problema si configura la penalización de la manera correcta. El primer enfoque que se utilizó en este tipo de regresión penalizada es ajustar el modelo de regresión. Aquí nuevamente, estamos penalizando una distancia entre nuestro resultado y y nuestro modelo de regresión aquí. Y luego también tenemos un término aquí. Eso es lambda multiplicado por la suma de los beta j al cuadrado. ¿Entonces, qué significa esto? Si los cuadrados de la beta j son realmente grandes, entonces este término se volverá demasiado grande, por lo que obtendremos, no obtendremos un ajuste muy bueno. Toda esta cantidad terminará siendo muy grande, por lo que básicamente requiere que algunas de las beta j sean pequeñas.

#En realidad, es equivalente a resolver este problema en el que buscamos la suma más pequeña de las diferencias al cuadrado aquí y la suma de las diferencias al cuadrado aquí. Sujeto a una restricción particular de que, la suma de beta j al cuadrado es menor que s. Entonces, la idea aquí es que la inclusión de este coeficiente lambda también puede hacer que el problema no sea singular. Incluso cuando la transposición x x no es invertible. En otras palabras, en ese ajuste del modelo donde tenemos más predictores que observaciones, el modelo de regresión de crestas aún se puede ajustar. Así que así es como se ve la ruta del coeficiente. Entonces, ¿qué quiero decir con ruta de coeficiente? Para cada elección diferente de lamda, ese problema de regresión penalizado en la página anterior, a medida que aumenta el gambito. Eso significa que penalizamos cada vez más a los grandes datos. Entonces, comenzamos con las betas iguales a ciertos valores aquí cuando lambda es igual a 0. Eso es solo un lineal estándar con valores de regresión. Y a medida que aumenta lambda, todos los coeficientes se acercan a 0. Porque estamos penalizando los coeficientes, y los hacemos y los hacemos más pequeños. Entonces, el parámetro de ajuste lambda controla el tamaño de los coeficientes de control. Lambda controla la cantidad de regularización. A medida que lambda se acerca cada vez más a 0, básicamente volvemos a la solución de mínimos cuadrados, que es lo que se obtiene de un modelo lineal estándar. Y como lambda va infinitamente a nosotros básicamente, en otras palabras, lambda se vuelve realmente grande. Penaliza mucho a los coeficientes, por lo que todos los coeficientes condicionados van hacia 0 a medida que el parámetro de ajuste se vuelve realmente grande. Entonces, tomar ese parámetro se puede hacer con validación cruzada u otras técnicas para tratar de elegir el parámetro de ajuste óptimo. Eso intercambia sesgo por varianza. Se puede hacer un enfoque similar con un ligero cambio de penalización. De nuevo, aquí podríamos estar resolviendo el problema nuevamente, este problema de cuadrados. Este es el estándar que intenta identificar los valores beta que hacen que esta distancia al resultado sea la más pequeña. Y aquí podemos restringirlo sujeto a que la suma del valor absoluto de los beta j sea menor que el valor de la suma. También puede escribir eso como una regresión penalizada de esta forma, por lo que estamos tratando de resolver esta suma penalizada de cuadrados. Entonces, para la matriz de diseño orto normal que puede, consulte en Wikipedia o la matriz de diseño normal. La idea es que esto realmente tenga una solución de forma cerrada. Y la solución de forma cerrada es básicamente, tomar el valor absoluto de la beta j y restar un valor gamma. Y tome solo la parte positiva. En otras palabras, si gamma es mayor que su beta de mínimos cuadrados hat j, entonces este será un número negativo. Y está tomando solo la parte positiva, por lo que lo establece igual a 0. Entonces, si es positivo, si esta beta absoluta hat j es mayor que, el valor gamma. Entonces este número entero será un número positivo más pequeño. Se reducirá en la cantidad gamma. Y luego, lo multiplicamos por el signo del coeficiente original. Entonces, ¿qué está haciendo esto? Básicamente está diciendo que el lazo reduce todos los coeficientes y establece algunos de ellos exactamente en 0. Y a algunas personas les gusta este enfoque porque ambos reducen los coeficientes. Y al establecer algo exactamente en 0, realiza la selección del modelo por adelantado. Hay muy buenas notas de conferencias de Héctor Corrada Bravo. Eso lo puedes encontrar aquí en este enlace. También tiene una lista muy buena sobre la gran cantidad de modelos de regresión penalizados. Y en el libro Elements of Statistical Learning cubre esta idea de regresión penalizada con un detalle bastante extenso. Si quieres seguir allí. En caret, si desea ajustar estos modelos, puede establecer el método en cresta, lazo o relaxo para adaptarse a diferentes tipos de modelos de regresión penalizados.
